# üß™ Gu√≠a de A/B Testing - Sistema ML

## üìã Introducci√≥n

El framework de A/B Testing permite validar el impacto real de las predicciones ML en el negocio mediante experimentos controlados. Compara un **grupo de control** (sin ML) vs un **grupo de tratamiento** (con ML) para medir m√©tricas clave.

---

## üéØ Tipos de Experimentos

### 1. **Precios Din√°micos**
- **Hip√≥tesis:** Los precios sugeridos por el modelo Ridge aumentan el revenue sin afectar la demanda
- **Grupo Control:** Precios fijos tradicionales
- **Grupo Tratamiento:** Precios sugeridos por ML
- **M√©tricas:** Revenue promedio, pedidos, satisfacci√≥n del cliente

### 2. **Alertas de Churn**
- **Hip√≥tesis:** Alertas proactivas de churn reducen la tasa de abandono
- **Grupo Control:** Sin alertas (gesti√≥n reactiva)
- **Grupo Tratamiento:** Alertas ML + acciones de retenci√≥n
- **M√©tricas:** Churn rate, revenue retenido, ROI de retenci√≥n

### 3. **Forecast de Demanda** (Futuro)
- **Hip√≥tesis:** Optimizar inventario seg√∫n forecast reduce costos y mejora servicio
- **Grupo Control:** Inventario basado en hist√≥rico
- **Grupo Tratamiento:** Inventario basado en forecast ML
- **M√©tricas:** Stock-outs, exceso de inventario, costos

---

## üöÄ Crear un Experimento

### Desde Python

```python
from ab_testing_framework import create_dynamic_pricing_experiment
from datetime import datetime

# 1. Obtener lista de clientes (desde Supabase)
customer_ids = ["customer_1", "customer_2", ..., "customer_100"]

# 2. Crear experimento
experiment = create_dynamic_pricing_experiment(
    customer_ids=customer_ids,
    start_date=datetime(2025, 11, 5),
    duration_days=30
)

# 3. El experimento asigna autom√°ticamente grupos y guarda
print(f"Experimento creado: {experiment.experiment_id}")
print(f"Control: {len(experiment.control_group)} clientes")
print(f"Treatment: {len(experiment.treatment_group)} clientes")
```

### Desde Frontend (integraci√≥n futura)

```typescript
// API endpoint para crear experimento
const createExperiment = async () => {
  const response = await fetch('/api/ml/experiments', {
    method: 'POST',
    body: JSON.stringify({
      type: 'dynamic_pricing',
      name: 'Precios Din√°micos Q4',
      duration_days: 30
    })
  });
  
  const experiment = await response.json();
  console.log('Experimento creado:', experiment.experiment_id);
};
```

---

## üìä Registrar Resultados

### Durante la Creaci√≥n de un Pedido

Cuando un cliente del experimento crea un pedido, registrar el outcome:

```python
from ab_testing_framework import ABTestExperiment
from datetime import datetime

# 1. Cargar experimento activo
experiment = ABTestExperiment.load_experiment("dynamic_pricing_20251105")

# 2. Registrar outcome del pedido
experiment.record_outcome(
    customer_id="customer_42",
    outcome={
        "revenue": 45000,
        "orders_count": 1,
        "churned": False,
        "timestamp": datetime.now()
    }
)

# 3. Guardar experimento actualizado
experiment.save_experiment()
```

### Desde el Frontend (integraci√≥n futura)

```typescript
// Hook para registrar outcome
const recordExperimentOutcome = async (orderId: string) => {
  await fetch(`/api/ml/experiments/${experimentId}/outcomes`, {
    method: 'POST',
    body: JSON.stringify({
      customer_id: customerId,
      revenue: finalPrice,
      orders_count: 1,
      churned: false,
      timestamp: new Date().toISOString()
    })
  });
};
```

---

## üìà Calcular M√©tricas

### Al Final del Experimento

```python
from ab_testing_framework import ABTestExperiment

# 1. Cargar experimento
experiment = ABTestExperiment.load_experiment("dynamic_pricing_20251105")

# 2. Calcular m√©tricas
metrics = experiment.calculate_metrics()

print(f"Control Revenue Promedio: ${metrics['control']['avg_revenue_per_customer']:,.0f}")
print(f"Treatment Revenue Promedio: ${metrics['treatment']['avg_revenue_per_customer']:,.0f}")
print(f"Revenue Uplift: {metrics['uplift']['revenue_uplift_pct']:+.1f}%")
```

### Generar Reporte

```python
# 3. Generar reporte detallado
report_path = experiment.generate_report()
print(f"Reporte guardado en: {report_path}")
```

---

## üîß Integraci√≥n con el Sistema 3T

### 1. **Verificar Grupo de Experimento al Crear Pedido**

En el frontend, antes de mostrar el precio:

```typescript
// lib/ml-api-client.ts
export async function getExperimentPrice(customerId: string, quantity: number) {
  // Verificar si hay experimento activo
  const activeExperiment = await fetch('/api/ml/experiments/active').then(r => r.json());
  
  if (activeExperiment && activeExperiment.type === 'dynamic_pricing') {
    // Verificar si el cliente est√° en treatment
    const isInTreatment = activeExperiment.treatment_group.includes(customerId);
    
    if (isInTreatment) {
      // Usar precio ML
      const mlPrice = await mlApi.suggestPrice({ customer_id: customerId, quantity });
      return mlPrice.suggested_price;
    }
  }
  
  // Control: precio tradicional
  return getTraditionalPrice(quantity);
}
```

### 2. **Registrar Outcome al Confirmar Pedido**

En el servidor (API route):

```typescript
// app/api/orders/route.ts
export async function POST(request: Request) {
  const order = await request.json();
  
  // ... crear pedido en Supabase ...
  
  // Registrar en experimento si aplica
  const activeExperiment = await getActiveExperiment();
  if (activeExperiment) {
    await recordExperimentOutcome({
      experiment_id: activeExperiment.id,
      customer_id: order.customer_id,
      revenue: order.final_price,
      orders_count: 1,
      churned: false
    });
  }
  
  return Response.json({ success: true });
}
```

### 3. **Dashboard de Experimentos** (Futuro)

Agregar vista en el frontend para monitorear experimentos activos:

```
/ml-insights/experiments
  ‚Üí Lista de experimentos activos
  ‚Üí M√©tricas en tiempo real
  ‚Üí Gr√°ficos de uplift
  ‚Üí Bot√≥n para finalizar experimento
```

---

## üìã Checklist de Experimento

### Antes de Lanzar
- [ ] Definir hip√≥tesis clara
- [ ] Calcular tama√±o de muestra necesario
- [ ] Configurar duraci√≥n del experimento (m√≠nimo 2 semanas)
- [ ] Validar asignaci√≥n de grupos (50/50 por defecto)
- [ ] Definir m√©tricas de √©xito
- [ ] Comunicar al equipo sobre el experimento

### Durante el Experimento
- [ ] Monitorear registro de outcomes diariamente
- [ ] Verificar que ambos grupos tengan datos
- [ ] No modificar el experimento (mantener integridad)
- [ ] Registrar observaciones cualitativas

### Al Finalizar
- [ ] Calcular m√©tricas finales
- [ ] Generar reporte
- [ ] Validar significancia estad√≠stica (futuro: test chi-cuadrado)
- [ ] Presentar resultados al equipo
- [ ] Decidir: Implementar / Iterar / Descartar

---

## üìä Ejemplo Real: Precios Din√°micos

### Configuraci√≥n

```python
# Experimento: Validar precios ML vs precios fijos
# Duraci√≥n: 30 d√≠as
# Clientes: 100 (50 control, 50 treatment)

experiment = create_dynamic_pricing_experiment(
    customer_ids=all_customers,
    start_date=datetime(2025, 11, 5),
    duration_days=30
)
```

### Resultados Esperados

| M√©trica | Control | Treatment | Uplift |
|---------|---------|-----------|--------|
| Revenue Promedio | $35,000 | $38,500 | **+10%** |
| Pedidos | 150 | 165 | +10% |
| Churn Rate | 12% | 11% | -1% |

### Decisi√≥n

‚úÖ **Uplift positivo >5%** ‚Üí Implementar precios ML en producci√≥n

‚ö†Ô∏è **Uplift 0-5%** ‚Üí Iterar y mejorar modelo

‚ùå **Uplift negativo** ‚Üí Mantener precios fijos

---

## üîÆ Pr√≥ximas Mejoras

1. **Significancia Estad√≠stica:** Agregar tests estad√≠sticos (chi-cuadrado, t-test)
2. **Tama√±o de Muestra:** Calculadora de tama√±o de muestra √≥ptimo
3. **Multi-Armed Bandit:** Optimizaci√≥n din√°mica de asignaci√≥n de grupos
4. **Dashboard Web:** Visualizaci√≥n en tiempo real de experimentos
5. **Integraci√≥n n8n:** Notificaciones autom√°ticas de resultados

---

## üìö Referencias

- **A/B Testing Best Practices**: [Optimizely Guide](https://www.optimizely.com/optimization-glossary/ab-testing/)
- **Statistical Significance**: [Evan Miller Calculator](https://www.evanmiller.org/ab-testing/)
- **Experiment Design**: [Google's Best Practices](https://developers.google.com/analytics/devguides/collection/analyticsjs/experiments)

---

**√öltima actualizaci√≥n:** 2025-11-04
**Versi√≥n:** 1.0.0

